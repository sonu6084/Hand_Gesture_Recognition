{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Importing Libraries\n",
    "import os\n",
    "import time\n",
    "import cv2\n",
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "\n",
    "import matplotlib.image as mpimg \n",
    "import matplotlib.pyplot as plt \n",
    "from keras.utils import np_utils\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "written in disk-punch\n",
      "Exiting the setup....\n"
     ]
    }
   ],
   "source": [
    "#data collection\n",
    "def display_info(arg):\n",
    "    button={\n",
    "    0:\"     \",\n",
    "    1:'palm_'+str(palm_counter),\n",
    "    2:'ok_'+str(ok_counter),\n",
    "    3:'peace_'+str(peace_counter),\n",
    "    4:'punch_'+str(punch_counter),\n",
    "    5:'thumb_'+str(thumb_counter),\n",
    "    6:'right_'+str(right_counter)\n",
    "    }\n",
    "    return button.get(arg)\n",
    "\n",
    "\n",
    "#paths for training folder\n",
    "path_train='./Images/image_train/'\n",
    "path_test='./Images/image_test/'\n",
    "path_palm = path_train+'palm/'\n",
    "path_ok = path_train+'ok/'\n",
    "path_peace = path_train+'peace/'\n",
    "path_punch = path_train+'punch/'\n",
    "path_thumb = path_train+'thumbs_up/'\n",
    "path_right = path_train+'right/'\n",
    "\n",
    "#image numbers counters in directory\n",
    "palm_counter=0\n",
    "ok_counter=0\n",
    "peace_counter=0\n",
    "punch_counter=0\n",
    "thumb_counter=0\n",
    "right_counter=0\n",
    "\n",
    "#number of images present in directory\n",
    "for files in os.listdir(path_palm):\n",
    "    palm_counter=palm_counter+1\n",
    "    \n",
    "for files in os.listdir(path_ok):\n",
    "    ok_counter=ok_counter+1\n",
    "    \n",
    "for files in os.listdir(path_peace):\n",
    "    peace_counter=peace_counter+1\n",
    "    \n",
    "for files in os.listdir(path_punch):\n",
    "    punch_counter=punch_counter+1\n",
    "    \n",
    "for files in os.listdir(path_thumb):\n",
    "    thumb_counter=thumb_counter+1\n",
    "    \n",
    "for files in os.listdir(path_right):\n",
    "    right_counter=right_counter+1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "cam=cv2.VideoCapture(0)\n",
    "button_pressed=0\n",
    "\n",
    "\n",
    "\n",
    "upper_left=(0,100)\n",
    "bottom_right=(250,350)\n",
    "while True:\n",
    "    ret,frame=cam.read()\n",
    "    cv2.rectangle(img=frame,pt1=upper_left,pt2=bottom_right,color=(255,0,0),thickness=1)\n",
    "    \n",
    "    \n",
    "    show_text=display_info(button_pressed)\n",
    "    \n",
    "    fonts=cv2.FONT_HERSHEY_COMPLEX_SMALL\n",
    "    cv2.putText(img=frame,text=show_text,org=(10,370),fontFace=fonts,fontScale=1,color=(255,0,0),thickness=1)\n",
    "    \n",
    "    cv2.imshow('Webcam',frame)\n",
    "    roi=frame[upper_left[1]:bottom_right[1],upper_left[0]:bottom_right[0]]\n",
    "    cv2.imshow('roi',roi)\n",
    "    \n",
    "    lower = np.array([0, 10, 60], dtype = \"uint8\") #for skin color\n",
    "    upper = np.array([20, 150, 255], dtype = \"uint8\")\n",
    "    hsv=cv2.cvtColor(roi,cv2.COLOR_BGR2HSV)    \n",
    "    mask=cv2.inRange(hsv,lower,upper)\n",
    "        \n",
    "    res=cv2.bitwise_and(roi,roi,mask=mask)\n",
    "    median=cv2.medianBlur(res,15)\n",
    "    lower2=np.array([20,40,80],dtype=\"uint8\")\n",
    "    upper2=np.array([140,170,200],dtype=\"uint8\")\n",
    "    mask2=cv2.inRange(median,lower2,upper2)\n",
    "    res2=cv2.bitwise_and(median,median,mask=mask2)\n",
    "        \n",
    "        \n",
    "    cv2.imshow('mask',mask)\n",
    "    cv2.imshow('mask2',mask2)\n",
    "    \n",
    "   \n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    k=cv2.waitKey(1)\n",
    "    if k%256 ==27:\n",
    "        print('Exiting the setup....')\n",
    "        break\n",
    "    elif k%256 ==ord('1'):\n",
    "        cv2.imwrite(path_palm+'palm_{}.png'.format( palm_counter),roi)\n",
    "        \n",
    "        palm_counter=palm_counter+1\n",
    "        print(\"written in disk-palm\")\n",
    "        button_pressed=1\n",
    "    elif k%256 ==ord('2'):\n",
    "        cv2.imwrite(path_ok+'ok_{}.png'.format( ok_counter),roi)\n",
    "        ok_counter=ok_counter+1\n",
    "        print(\"written in disk-ok\")\n",
    "        button_pressed=2\n",
    "    elif k%256 ==ord('3'):\n",
    "        cv2.imwrite(path_peace+'peace_{}.png'.format( peace_counter),roi)\n",
    "        peace_counter=peace_counter+1\n",
    "        print(\"written in disk-peace\")\n",
    "        button_pressed=3\n",
    "    elif k%256 ==ord('4'):\n",
    "        cv2.imwrite(path_punch+'punch_{}.png'.format( punch_counter),roi)\n",
    "        punch_counter=punch_counter+1\n",
    "        print(\"written in disk-punch\")\n",
    "        button_pressed=4\n",
    "    elif k%256 ==ord('5'):\n",
    "        cv2.imwrite(path_thumb+'thumb_{}.png'.format( thumb_counter),roi)\n",
    "        thumb_counter=thumb_counter+1\n",
    "        print(\"written in disk-thumb\")\n",
    "        button_pressed=5\n",
    "    elif k%256 ==ord('6'):\n",
    "        cv2.imwrite(path_right+'right_{}.png'.format( right_counter),roi)\n",
    "        right_counter=right_counter+1\n",
    "        print(\"written in disk-right\")\n",
    "        button_pressed=6\n",
    "\n",
    "cam.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "palm_0.png\n",
      "palm_1.png\n",
      "palm_10.png\n",
      "palm_11.png\n",
      "palm_12.png\n",
      "palm_13.png\n",
      "palm_14.png\n",
      "palm_15.png\n",
      "palm_16.png\n",
      "palm_17.png\n",
      "palm_18.png\n",
      "palm_19.png\n",
      "palm_2.png\n",
      "palm_20.png\n",
      "palm_21.png\n",
      "palm_22.png\n",
      "palm_23.png\n",
      "palm_24.png\n",
      "palm_25.png\n",
      "palm_26.png\n",
      "palm_27.png\n",
      "palm_28.png\n",
      "palm_29.png\n",
      "palm_3.png\n",
      "palm_30.png\n",
      "palm_31.png\n",
      "palm_32.png\n",
      "palm_33.png\n",
      "palm_34.png\n",
      "palm_35.png\n",
      "palm_36.png\n",
      "palm_37.png\n",
      "palm_38.png\n",
      "palm_39.png\n",
      "palm_4.png\n",
      "palm_40.png\n",
      "palm_41.png\n",
      "palm_42.png\n",
      "palm_43.png\n",
      "palm_44.png\n",
      "palm_45.png\n",
      "palm_46.png\n",
      "palm_47.png\n",
      "palm_48.png\n",
      "palm_49.png\n",
      "palm_5.png\n",
      "palm_50.png\n",
      "palm_51.png\n",
      "palm_52.png\n",
      "palm_53.png\n",
      "palm_54.png\n",
      "palm_55.png\n",
      "palm_56.png\n",
      "palm_57.png\n",
      "palm_58.png\n",
      "palm_59.png\n",
      "palm_6.png\n",
      "palm_60.png\n",
      "palm_7.png\n",
      "palm_8.png\n",
      "palm_9.png\n",
      "ok_0.png\n",
      "ok_1.png\n",
      "ok_10.png\n",
      "ok_11.png\n",
      "ok_12.png\n",
      "ok_13.png\n",
      "ok_14.png\n",
      "ok_15.png\n",
      "ok_16.png\n",
      "ok_17.png\n",
      "ok_18.png\n",
      "ok_19.png\n",
      "ok_2.png\n",
      "ok_20.png\n",
      "ok_21.png\n",
      "ok_22.png\n",
      "ok_23.png\n",
      "ok_24.png\n",
      "ok_25.png\n",
      "ok_26.png\n",
      "ok_27.png\n",
      "ok_28.png\n",
      "ok_29.png\n",
      "ok_3.png\n",
      "ok_30.png\n",
      "ok_31.png\n",
      "ok_32.png\n",
      "ok_33.png\n",
      "ok_34.png\n",
      "ok_35.png\n",
      "ok_36.png\n",
      "ok_37.png\n",
      "ok_38.png\n",
      "ok_39.png\n",
      "ok_4.png\n",
      "ok_40.png\n",
      "ok_41.png\n",
      "ok_42.png\n",
      "ok_43.png\n",
      "ok_44.png\n",
      "ok_45.png\n",
      "ok_46.png\n",
      "ok_47.png\n",
      "ok_48.png\n",
      "ok_49.png\n",
      "ok_5.png\n",
      "ok_50.png\n",
      "ok_51.png\n",
      "ok_52.png\n",
      "ok_53.png\n",
      "ok_54.png\n",
      "ok_55.png\n",
      "ok_56.png\n",
      "ok_57.png\n",
      "ok_58.png\n",
      "ok_59.png\n",
      "ok_6.png\n",
      "ok_7.png\n",
      "ok_8.png\n",
      "ok_9.png\n",
      "peace_0.png\n",
      "peace_1.png\n",
      "peace_10.png\n",
      "peace_11.png\n",
      "peace_12.png\n",
      "peace_13.png\n",
      "peace_14.png\n",
      "peace_15.png\n",
      "peace_16.png\n",
      "peace_17.png\n",
      "peace_18.png\n",
      "peace_19.png\n",
      "peace_2.png\n",
      "peace_20.png\n",
      "peace_21.png\n",
      "peace_22.png\n",
      "peace_23.png\n",
      "peace_24.png\n",
      "peace_25.png\n",
      "peace_26.png\n",
      "peace_27.png\n",
      "peace_28.png\n",
      "peace_29.png\n",
      "peace_3.png\n",
      "peace_30.png\n",
      "peace_31.png\n",
      "peace_32.png\n",
      "peace_33.png\n",
      "peace_34.png\n",
      "peace_35.png\n",
      "peace_36.png\n",
      "peace_37.png\n",
      "peace_38.png\n",
      "peace_39.png\n",
      "peace_4.png\n",
      "peace_40.png\n",
      "peace_41.png\n",
      "peace_42.png\n",
      "peace_43.png\n",
      "peace_44.png\n",
      "peace_45.png\n",
      "peace_46.png\n",
      "peace_47.png\n",
      "peace_48.png\n",
      "peace_49.png\n",
      "peace_5.png\n",
      "peace_50.png\n",
      "peace_51.png\n",
      "peace_52.png\n",
      "peace_53.png\n",
      "peace_54.png\n",
      "peace_55.png\n",
      "peace_56.png\n",
      "peace_57.png\n",
      "peace_58.png\n",
      "peace_59.png\n",
      "peace_6.png\n",
      "peace_7.png\n",
      "peace_8.png\n",
      "peace_9.png\n",
      "thumb_0.png\n",
      "thumb_1.png\n",
      "thumb_10.png\n",
      "thumb_11.png\n",
      "thumb_12.png\n",
      "thumb_13.png\n",
      "thumb_14.png\n",
      "thumb_15.png\n",
      "thumb_16.png\n",
      "thumb_17.png\n",
      "thumb_18.png\n",
      "thumb_19.png\n",
      "thumb_2.png\n",
      "thumb_20.png\n",
      "thumb_21.png\n",
      "thumb_22.png\n",
      "thumb_23.png\n",
      "thumb_24.png\n",
      "thumb_25.png\n",
      "thumb_26.png\n",
      "thumb_27.png\n",
      "thumb_28.png\n",
      "thumb_29.png\n",
      "thumb_3.png\n",
      "thumb_30.png\n",
      "thumb_31.png\n",
      "thumb_32.png\n",
      "thumb_33.png\n",
      "thumb_34.png\n",
      "thumb_35.png\n",
      "thumb_36.png\n",
      "thumb_37.png\n",
      "thumb_38.png\n",
      "thumb_39.png\n",
      "thumb_4.png\n",
      "thumb_40.png\n",
      "thumb_41.png\n",
      "thumb_42.png\n",
      "thumb_43.png\n",
      "thumb_44.png\n",
      "thumb_45.png\n",
      "thumb_46.png\n",
      "thumb_47.png\n",
      "thumb_48.png\n",
      "thumb_49.png\n",
      "thumb_5.png\n",
      "thumb_50.png\n",
      "thumb_51.png\n",
      "thumb_52.png\n",
      "thumb_53.png\n",
      "thumb_54.png\n",
      "thumb_55.png\n",
      "thumb_56.png\n",
      "thumb_57.png\n",
      "thumb_58.png\n",
      "thumb_59.png\n",
      "thumb_6.png\n",
      "thumb_60.png\n",
      "thumb_61.png\n",
      "thumb_7.png\n",
      "thumb_8.png\n",
      "thumb_9.png\n",
      "punch_0.png\n",
      "punch_1.png\n",
      "punch_10.png\n",
      "punch_11.png\n",
      "punch_12.png\n",
      "punch_13.png\n",
      "punch_14.png\n",
      "punch_15.png\n",
      "punch_16.png\n",
      "punch_17.png\n",
      "punch_18.png\n",
      "punch_19.png\n",
      "punch_2.png\n",
      "punch_20.png\n",
      "punch_21.png\n",
      "punch_22.png\n",
      "punch_23.png\n",
      "punch_24.png\n",
      "punch_25.png\n",
      "punch_26.png\n",
      "punch_27.png\n",
      "punch_28.png\n",
      "punch_29.png\n",
      "punch_3.png\n",
      "punch_30.png\n",
      "punch_31.png\n",
      "punch_32.png\n",
      "punch_33.png\n",
      "punch_34.png\n",
      "punch_35.png\n",
      "punch_36.png\n",
      "punch_37.png\n",
      "punch_38.png\n",
      "punch_39.png\n",
      "punch_4.png\n",
      "punch_40.png\n",
      "punch_41.png\n",
      "punch_42.png\n",
      "punch_43.png\n",
      "punch_44.png\n",
      "punch_45.png\n",
      "punch_46.png\n",
      "punch_47.png\n",
      "punch_48.png\n",
      "punch_49.png\n",
      "punch_5.png\n",
      "punch_50.png\n",
      "punch_51.png\n",
      "punch_52.png\n",
      "punch_53.png\n",
      "punch_54.png\n",
      "punch_55.png\n",
      "punch_56.png\n",
      "punch_57.png\n",
      "punch_58.png\n",
      "punch_59.png\n",
      "punch_6.png\n",
      "punch_60.png\n",
      "punch_61.png\n",
      "punch_7.png\n",
      "punch_8.png\n",
      "punch_9.png\n",
      "right_0.png\n",
      "right_1.png\n",
      "right_10.png\n",
      "right_11.png\n",
      "right_12.png\n",
      "right_13.png\n",
      "right_14.png\n",
      "right_15.png\n",
      "right_16.png\n",
      "right_17.png\n",
      "right_18.png\n",
      "right_19.png\n",
      "right_2.png\n",
      "right_20.png\n",
      "right_21.png\n",
      "right_22.png\n",
      "right_23.png\n",
      "right_24.png\n",
      "right_25.png\n",
      "right_26.png\n",
      "right_27.png\n",
      "right_28.png\n",
      "right_29.png\n",
      "right_3.png\n",
      "right_30.png\n",
      "right_31.png\n",
      "right_32.png\n",
      "right_33.png\n",
      "right_34.png\n",
      "right_35.png\n",
      "right_36.png\n",
      "right_37.png\n",
      "right_38.png\n",
      "right_39.png\n",
      "right_4.png\n",
      "right_40.png\n",
      "right_41.png\n",
      "right_42.png\n",
      "right_43.png\n",
      "right_44.png\n",
      "right_45.png\n",
      "right_46.png\n",
      "right_47.png\n",
      "right_48.png\n",
      "right_49.png\n",
      "right_5.png\n",
      "right_50.png\n",
      "right_51.png\n",
      "right_52.png\n",
      "right_53.png\n",
      "right_54.png\n",
      "right_55.png\n",
      "right_56.png\n",
      "right_57.png\n",
      "right_58.png\n",
      "right_59.png\n",
      "right_6.png\n",
      "right_60.png\n",
      "right_7.png\n",
      "right_8.png\n",
      "right_9.png\n"
     ]
    }
   ],
   "source": [
    "#converting color image to mask image\n",
    "\n",
    "#variables containing directories \n",
    "path_drive='\\\\content\\\\drive\\\\My Drive\\\\Handy\\\\Handy'\n",
    "path_train='.\\\\Images\\\\image_train\\\\'\n",
    "path_test='.\\\\Images\\\\image_test\\\\'\n",
    "path_palm = path_train+'palm\\\\'\n",
    "path_ok = path_train+'ok\\\\'\n",
    "path_peace = path_train+'peace\\\\'\n",
    "path_punch = path_train+'punch\\\\'\n",
    "path_thumbs_up = path_train+'thumbs_up\\\\'\n",
    "path_right = path_train+'right\\\\'\n",
    "\n",
    "\n",
    "path_train_converted='.\\\\Images\\\\image_train_converted\\\\'\n",
    "path_test_converted='.\\\\Images\\\\image_test_converted\\\\'\n",
    "path_converted_palm = path_train_converted+'palm\\\\'\n",
    "path_converted_ok = path_train_converted+'ok\\\\'\n",
    "path_converted_peace = path_train_converted+'peace\\\\'\n",
    "path_converted_punch = path_train_converted+'punch\\\\'\n",
    "path_converted_thumbs_up = path_train_converted+'thumbs_up\\\\'\n",
    "path_converted_right = path_train_converted+'right\\\\'\n",
    "\n",
    "\n",
    "\n",
    "def color_to_mask(path_og,path_converted,im_type):\n",
    "    i=0\n",
    "    for files in os.listdir(path_og):\n",
    "        print(files)\n",
    "        \n",
    "        img2=image.load_img(os.path.join(path_og+\"{}_{}.png\".format(im_type,i)),target_size=(64,64))\n",
    "        img2=np.array(img2)\n",
    "\n",
    "        img2=cv2.cvtColor(img2,cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        \n",
    "        lower = np.array([0, 10, 60], dtype = \"uint8\") #for skin color\n",
    "        upper = np.array([20, 150, 255], dtype = \"uint8\")\n",
    "        hsv=cv2.cvtColor(img2,cv2.COLOR_BGR2HSV)    \n",
    "        mask=cv2.inRange(hsv,lower,upper)\n",
    "\n",
    "        \n",
    "        cv2.imwrite(path_converted+'{}_{}.png'.format(im_type,i),mask)\n",
    "        \n",
    "        i=i+1\n",
    "        cv2.waitKey(0)\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "color_to_mask(path_palm,path_converted_palm,'palm')    \n",
    "color_to_mask(path_ok,path_converted_ok,'ok')\n",
    "color_to_mask(path_peace,path_converted_peace,'peace')\n",
    "color_to_mask(path_thumbs_up,path_converted_thumbs_up,'thumb')\n",
    "color_to_mask(path_punch,path_converted_punch,'punch')\n",
    "color_to_mask(path_right,path_converted_right,'right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 62, 62, 16)        160       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 60, 60, 16)        2320      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 30, 30, 16)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 30, 30, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 28, 28, 32)        4640      \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 26, 26, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                102464    \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 6)                 390       \n",
      "=================================================================\n",
      "Total params: 137,718\n",
      "Trainable params: 137,718\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#creating model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(filters=16, kernel_size=(3,3), activation=\"relu\", input_shape=(64,64,1)))\n",
    "model.add(Conv2D(filters=16, kernel_size=(3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv2D(filters=32, kernel_size=(3,3), activation='relu'))\n",
    "model.add(Conv2D(filters=32, kernel_size=(3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv2D(filters=64, kernel_size=(3,3), activation=\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(6, activation='sigmoid'))\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_train_converted='.\\\\Images\\\\image_train_converted\\\\'\n",
    "path_test_converted='.\\\\Images\\\\image_test_converted\\\\'\n",
    "path_converted_palm = path_train_converted+'palm\\\\'\n",
    "path_converted_ok = path_train_converted+'ok\\\\'\n",
    "path_converted_peace = path_train_converted+'peace\\\\'\n",
    "path_converted_punch = path_train_converted+'punch\\\\'\n",
    "path_converted_thumbs_up = path_train_converted+'thumbs_up\\\\'\n",
    "path_converted_right = path_train_converted+'right\\\\'\n",
    "\n",
    "\n",
    "\n",
    "result_dic={\n",
    "0 : \"palm\",\n",
    "1 : \"ok\",\n",
    "2 : \"peace\",\n",
    "3 : \"punch\",\n",
    "4 : \"thumbs_up\",\n",
    "5 : \"right\"\n",
    "}\n",
    "\n",
    "initial_dic={\n",
    "\"palm\" : 0,\n",
    "\"ok\" : 1,\n",
    "\"peace\" : 2,\n",
    "\"punch\" : 3,\n",
    "\"thumbs_up\" : 4,\n",
    "\"right\" : 5\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "dataset=[]\n",
    "y=[]\n",
    "i=[0]\n",
    "def creating_dataset(path_enter):\n",
    "    \n",
    "    for files in os.listdir(path_enter):\n",
    "        #img=image.load_img(files,target_size=(64,64))\n",
    "        img2=cv2.imread(os.path.join(path_enter ,files ),0)\n",
    "        #img2=cv2.cvtColor(img2,cv2.COLOR_RGB2GRAY)\n",
    "        img_array=image.img_to_array(img2)\n",
    "        dataset.append(img_array)\n",
    "        path_split=path_enter.split('\\\\')\n",
    "        y.append(initial_dic[path_split[-2].lower()])\n",
    "        i[0]=i[0]+1\n",
    "\n",
    "\n",
    "        \n",
    "creating_dataset(path_converted_palm)\n",
    "creating_dataset(path_converted_ok)\n",
    "creating_dataset(path_converted_peace)\n",
    "creating_dataset(path_converted_punch)\n",
    "creating_dataset(path_converted_right)\n",
    "creating_dataset(path_converted_thumbs_up)\n",
    "\n",
    "\n",
    "dataset_array=np.array(dataset)\n",
    "y=np.array(y)\n",
    "dataset_array=dataset_array/255\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split( dataset_array, y, test_size=0.1, random_state=0)\n",
    "\n",
    "\n",
    "y_train=np_utils.to_categorical(y_train,num_classes=6)    #converting array to 6 class array\n",
    "y_test=np_utils.to_categorical(y_test,num_classes=6)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compiling and fitting the model\n",
    "model.compile(optimizer=\"RMSprop\",loss=\"categorical_crossentropy\",metrics=[\"accuracy\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\nigam\\Anaconda3\\envs\\gputest\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Epoch 1/6\n",
      "329/329 [==============================] - 17s 51ms/step - loss: 1.5612 - accuracy: 0.3242 - val_loss: 1.0753 - val_accuracy: 0.6415\n",
      "Epoch 2/6\n",
      "329/329 [==============================] - 15s 46ms/step - loss: 1.2166 - accuracy: 0.4697 - val_loss: 0.7309 - val_accuracy: 0.8608\n",
      "Epoch 3/6\n",
      "329/329 [==============================] - 16s 48ms/step - loss: 1.0751 - accuracy: 0.5479 - val_loss: 0.8883 - val_accuracy: 0.7642\n",
      "Epoch 4/6\n",
      "329/329 [==============================] - 16s 47ms/step - loss: 0.9513 - accuracy: 0.6109 - val_loss: 0.5311 - val_accuracy: 0.8734\n",
      "Epoch 5/6\n",
      "329/329 [==============================] - 15s 46ms/step - loss: 0.8344 - accuracy: 0.6826 - val_loss: 0.4396 - val_accuracy: 0.9151\n",
      "Epoch 6/6\n",
      "329/329 [==============================] - 15s 45ms/step - loss: 0.7206 - accuracy: 0.7309 - val_loss: 0.1766 - val_accuracy: 0.8987\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a0b5b60fc8>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data augumentation\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    shear_range=0.1)\n",
    "\n",
    "val_datagen = ImageDataGenerator() \n",
    "val_datagen.fit(X_test)\n",
    "datagen.fit(X_train)\n",
    "\n",
    "model.fit_generator(datagen.flow(X_train, y_train),\n",
    "                    steps_per_epoch=len(X_train),\n",
    "                    epochs=6,\n",
    "                    validation_data=val_datagen.flow(X_test, y_test),\n",
    "                    validation_steps=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "#saving model to disk\n",
    "from keras.models import model_from_json\n",
    "model_json = model.to_json()\n",
    "with open(\".\\\\model_info\\\\hand_gesture_recognizer.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\".\\\\model_info\\\\hand_gesture_recognizer.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n"
     ]
    }
   ],
   "source": [
    "from keras.models import model_from_json\n",
    "\n",
    "json_file = open('.\\\\model_info\\\\hand_gesture_recognizer.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(\".\\\\model_info\\\\hand_gesture_recognizer.h5\")\n",
    "print(\"Loaded model from disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ok', 'right', 'palm', 'palm', 'ok', 'thumbs_up', 'ok', 'right', 'peace', 'palm', 'ok', 'peace', 'right', 'right', 'right', 'punch', 'right', 'ok', 'punch', 'peace', 'peace', 'punch', 'palm', 'right', 'right', 'right', 'ok', 'punch', 'ok', 'punch', 'peace', 'peace', 'palm', 'palm', 'palm', 'palm', 'palm']\n",
      "['ok', 'right', 'palm', 'palm', 'ok', 'thumbs_up', 'ok', 'thumbs_up', 'punch', 'palm', 'ok', 'peace', 'right', 'right', 'right', 'punch', 'right', 'ok', 'punch', 'peace', 'peace', 'punch', 'palm', 'right', 'right', 'right', 'ok', 'thumbs_up', 'ok', 'punch', 'peace', 'ok', 'palm', 'palm', 'palm', 'palm', 'palm']\n",
      "right,thumbs_up\n",
      "peace,punch\n",
      "punch,thumbs_up\n",
      "peace,ok\n",
      "33\n"
     ]
    }
   ],
   "source": [
    "result_dic={\n",
    "0 : \"palm\",\n",
    "1 : \"ok\",\n",
    "2 : \"peace\",\n",
    "3 : \"punch\",\n",
    "4 : \"thumbs_up\",\n",
    "5 : \"right\"\n",
    "}\n",
    "\n",
    "pred=loaded_model.predict(X_test)\n",
    "all_pred=[]\n",
    "for i in range(37):\n",
    "  all_pred.append(result_dic[pred[i].argmax()])\n",
    "\n",
    "print(all_pred)\n",
    "all_pred_true=[]\n",
    "for i in range(37):\n",
    "  all_pred_true.append(result_dic[y_test[i].argmax()])\n",
    "\n",
    "print(all_pred_true)\n",
    "\n",
    "count=0\n",
    "for i in range(37):\n",
    "  if all_pred[i]==all_pred_true[i]:\n",
    "    count=count+1\n",
    "  else:\n",
    "    print(all_pred[i]+\",\"+all_pred_true[i])\n",
    "\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 64)\n",
      "(64, 64, 1)\n",
      "palm\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from keras.preprocessing import image\n",
    "\n",
    "path_test='.\\\\image_test\\\\'\n",
    "path_palm_test = path_test+'palm\\\\'\n",
    "path_ok_test = path_test+'ok\\\\'\n",
    "path_peace_test = path_test+'peace\\\\'\n",
    "path_punch_test = path_test+'punch\\\\'\n",
    "path_thumb_test = path_test+'thumbs_up\\\\'\n",
    "path_right_test = path_test+'right\\\\'\n",
    "\n",
    "path_train_converted='.\\\\image_train_converted\\\\'\n",
    "path_test_converted='.\\\\image_test_converted\\\\'\n",
    "path_converted_palm = path_train_converted+'palm\\\\'\n",
    "\n",
    "\n",
    "def process_test(img):\n",
    "        lower = np.array([0, 10, 60], dtype = \"uint8\") #for skin color\n",
    "        upper = np.array([20, 150, 255], dtype = \"uint8\")\n",
    "        hsv=cv2.cvtColor(img,cv2.COLOR_BGR2HSV)    \n",
    "        mask=cv2.inRange(hsv,lower,upper)\n",
    "        \n",
    "        res=cv2.bitwise_and(img,img,mask=mask)\n",
    "        median=cv2.medianBlur(res,15)\n",
    "        lower2=np.array([20,40,80],dtype=\"uint8\")\n",
    "        upper2=np.array([140,170,200],dtype=\"uint8\")\n",
    "        mask2=cv2.inRange(median,lower2,upper2)\n",
    "\n",
    "        return mask\n",
    "\n",
    "\n",
    "img2=cv2.imread(os.path.join(path_converted_palm,\"palm_0.png\"),0)\n",
    "img2=np.array(img2)\n",
    "\n",
    "testing_image=[]\n",
    "\n",
    "img_array=image.img_to_array(img2)\n",
    "testing_image.append(img_array)\n",
    "testing_image=np.array(testing_image)\n",
    "\n",
    "print(img2.shape)\n",
    "\n",
    "testing_image = testing_image/255\n",
    "print(testing_image[0].shape)\n",
    "\n",
    "pred=loaded_model.predict(testing_image)\n",
    "print(result_dic[pred.argmax()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exiting the setup....\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "upper_left=(0,100)\n",
    "bottom_right=(250,350)\n",
    "while True:\n",
    "    ret,frame=cap.read()\n",
    "    cv2.rectangle(img=frame,pt1=upper_left,pt2=bottom_right,color=(255,0,0),thickness=1)\n",
    "    roi=frame[upper_left[1]:bottom_right[1],upper_left[0]:bottom_right[0]]\n",
    "    mask = process_test(roi)\n",
    "    \n",
    "    img2=np.array(mask)\n",
    "    resized = cv2.resize(img2, (64,64), interpolation = cv2.INTER_AREA)\n",
    "\n",
    "    testing_image=[]\n",
    "\n",
    "    img_array=image.img_to_array(resized)\n",
    "    testing_image.append(img_array)\n",
    "    testing_image=np.array(testing_image)\n",
    "    testing_image = testing_image/255\n",
    "    pred=loaded_model.predict(testing_image)\n",
    "    res=result_dic[pred.argmax()]\n",
    "    \n",
    "    fonts=cv2.FONT_HERSHEY_COMPLEX_SMALL\n",
    "    cv2.putText(img=frame,text=res,org=(10,370),fontFace=fonts,fontScale=1,color=(255,0,0),thickness=1)\n",
    "    \n",
    "    \n",
    "    cv2.imshow('Webcam',frame)\n",
    "    cv2.imshow('mask',mask)\n",
    "    k=cv2.waitKey(1)\n",
    "    if k%256 ==27:\n",
    "        print('Exiting the setup....')\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gputest",
   "language": "python",
   "name": "gputest"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
